{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0f847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: ru_matched (6102 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306/306 [43:49<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: en_matched (2218 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [16:46<00:00,  9.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: ru_en_matched (11837 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 592/592 [1:31:07<00:00,  9.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Проверка завершена! Результаты сохранены в: data/verified_skills.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Этот код проверяет кластеризацию вокруг скилов Кловери \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"  \n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 20\n",
    "REQUEST_DELAY = 3\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты эксперт по IT-навыкам и кластеризации данных. Проверь корректность сопоставления IT-навыков:\n",
    "1. Канон (canon_original) — это эталонный навык\n",
    "2. Синоним (synonym_original) — предлагаемое соответствие\n",
    "\n",
    "Для каждой пары выполни два действия:\n",
    "1. Проверка: является ли canon_original IT-навыком (IT-сфера: программирование, инфраструктура, данные, кибербезопасность и т.д.)\n",
    "2. Проверка: является ли synonym_original корректным синонимом canon_original\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"it_skill\": true/false, \"correct_cluster\": true/false},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    pairs = \"\\n\".join([f\"{i+1}. Канон: {row['canon_original']} | Синоним: {row['synonym_original']}\" \n",
    "                      for i, row in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Проверь следующие пары:\\n{pairs}\\n\\nОтвет строго в формате JSON с ключом 'results':\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=900):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            \n",
    "            # Удаляем возможные обёртки ```json\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "            \n",
    "            # Попытка \"почистить\" JSON\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "            \n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_excel(file_path, output_path):\n",
    "    all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "    matched_sheets = {name: df for name, df in all_sheets.items() if name.endswith('_matched')}\n",
    "    results = {}\n",
    "\n",
    "    for sheet_name, df in matched_sheets.items():\n",
    "        print(f\"\\nОбработка листа: {sheet_name} ({len(df)} строк)\")\n",
    "\n",
    "        df['IT'] = None\n",
    "        df['Mistral_check'] = None\n",
    "\n",
    "        for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "            batch = df.iloc[i:i+BATCH_SIZE].to_dict('records')\n",
    "            prompt = prepare_prompt(batch)\n",
    "            response = query_mistral(prompt)\n",
    "\n",
    "            if response and 'results' in response:\n",
    "                for j, item in enumerate(response['results'][:len(batch)]):\n",
    "                    idx = df.index[i + j]\n",
    "                    df.at[idx, 'IT'] = item.get('it_skill', False)\n",
    "                    df.at[idx, 'Mistral_check'] = item.get('correct_cluster', False)\n",
    "            else:\n",
    "                print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "            df.to_excel(output_path, index=False)\n",
    "\n",
    "            if i + BATCH_SIZE < len(df):\n",
    "                time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "        results[sheet_name] = df\n",
    "\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        for sheet_name, df in results.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/final_Up_skills_mapping_with_originals_no_new_cluster.xlsx\"\n",
    "    output_file = \"data/verified_skills.xlsx\"\n",
    "    verified_data = process_excel(input_file, output_file)\n",
    "    print(f\"\\n✅ Проверка завершена! Результаты сохранены в: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3f3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ru_matched = pd.read_excel('data/verified_skills.xlsx', sheet_name='ru_matched')\n",
    "df_en_matched = pd.read_excel('data/verified_skills.xlsx', sheet_name='en_matched')\n",
    "df_ru_en_matched = pd.read_excel('data/verified_skills.xlsx', sheet_name='ru_en_matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd0c7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>canon_original</th>\n",
       "      <th>synonym_original</th>\n",
       "      <th>IT</th>\n",
       "      <th>Mistral_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ru</td>\n",
       "      <td>Дизайн-мышление</td>\n",
       "      <td>Алгоритмическое мышление</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ru</td>\n",
       "      <td>Дизайн-мышление</td>\n",
       "      <td>коммерческое мышление</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ru</td>\n",
       "      <td>Дизайн-мышление</td>\n",
       "      <td>Гибкость мышления</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ru</td>\n",
       "      <td>Дизайн-мышление</td>\n",
       "      <td>Стратегическое мышление</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>Дизайн-мышление</td>\n",
       "      <td>- Аналитическое мышление;</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>ru</td>\n",
       "      <td>Методы экспертных оценок</td>\n",
       "      <td>Метод Центра оценки</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>ru</td>\n",
       "      <td>Установка и настройка системного ПО</td>\n",
       "      <td>Опыт установки и настройки пользовательского ПО</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>ru</td>\n",
       "      <td>Анализ процессов и их эффективности</td>\n",
       "      <td>Анализ проблем и их решение</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>ru</td>\n",
       "      <td>Негативное тестирование</td>\n",
       "      <td>Негативное тестирование</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>ru</td>\n",
       "      <td>Регистрация в сервисах сети интернет</td>\n",
       "      <td>Оперативный поиск информации в сети Интернет</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6102 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                        canon_original  \\\n",
       "0          ru                       Дизайн-мышление   \n",
       "1          ru                       Дизайн-мышление   \n",
       "2          ru                       Дизайн-мышление   \n",
       "3          ru                       Дизайн-мышление   \n",
       "4          ru                       Дизайн-мышление   \n",
       "...       ...                                   ...   \n",
       "6097       ru              Методы экспертных оценок   \n",
       "6098       ru   Установка и настройка системного ПО   \n",
       "6099       ru   Анализ процессов и их эффективности   \n",
       "6100       ru               Негативное тестирование   \n",
       "6101       ru  Регистрация в сервисах сети интернет   \n",
       "\n",
       "                                     synonym_original     IT  Mistral_check  \n",
       "0                            Алгоритмическое мышление  False          False  \n",
       "1                               коммерческое мышление  False          False  \n",
       "2                                   Гибкость мышления  False          False  \n",
       "3                             Стратегическое мышление  False          False  \n",
       "4                           - Аналитическое мышление;  False          False  \n",
       "...                                               ...    ...            ...  \n",
       "6097                              Метод Центра оценки   True          False  \n",
       "6098  Опыт установки и настройки пользовательского ПО   True          False  \n",
       "6099                      Анализ проблем и их решение   True          False  \n",
       "6100                          Негативное тестирование   True           True  \n",
       "6101     Оперативный поиск информации в сети Интернет  False          False  \n",
       "\n",
       "[6102 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ru_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eae2dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "match1 = df_ru_matched[df_ru_matched['Mistral_check'] == True]['canon_original'].nunique()\n",
    "print(match1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9c70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "match2 = df_en_matched[df_en_matched['Mistral_check'] == True]['canon_original'].nunique()\n",
    "print(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38a78c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "match3 = df_ru_en_matched[df_ru_en_matched['Mistral_check'] == True]['canon_original'].nunique()\n",
    "print(match3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cdbd487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068\n"
     ]
    }
   ],
   "source": [
    "total = match1 + match2 + match3\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: ru_clusters (1405 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [09:43<00:00, 10.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: en_clusters (2654 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [18:35<00:00, 10.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: ru_en_clusters (2538 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [16:06<00:00,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Проверка завершена! Результаты сохранены в: data/verified_clusters.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Это код проверяет превичную кластьеризацию раздельных навыков по ru, en, ru_en\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"  \n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 25\n",
    "REQUEST_DELAY = 3\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты эксперт по IT-навыкам и кластеризации данных. Проверь корректность сопоставления IT-навыков:\n",
    "1. Канон (proposed_canon) — это эталонный навык\n",
    "2. Синоним (skill_original) — предлагаемое соответствие\n",
    "\n",
    "Для каждой пары выполни два действия:\n",
    "1. Проверка: является ли proposed_canon IT-навыком (IT-сфера: программирование, инфраструктура, данные, кибербезопасность и т.д.)\n",
    "2. Проверка: является ли skill_original корректным синонимом proposed_canon\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"it_skill\": true/false, \"correct_cluster\": true/false},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    pairs = \"\\n\".join([f\"{i+1}. Канон: {row['proposed_canon']} | Синоним: {row['skill_original']}\" \n",
    "                      for i, row in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Проверь следующие пары:\\n{pairs}\\n\\nОтвет строго в формате JSON с ключом 'results':\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=950):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            \n",
    "            # Удаляем возможные обёртки ```json\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "            \n",
    "            # Попытка \"почистить\" JSON\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "            \n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_excel(file_path, output_path):\n",
    "    all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "    matched_sheets = {name: df for name, df in all_sheets.items() if name.endswith('_clusters')}\n",
    "    results = {}\n",
    "\n",
    "    for sheet_name, df in matched_sheets.items():\n",
    "        print(f\"\\nОбработка листа: {sheet_name} ({len(df)} строк)\")\n",
    "\n",
    "        df['IT'] = None\n",
    "        df['Mistral_check'] = None\n",
    "\n",
    "        for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "            batch = df.iloc[i:i+BATCH_SIZE].to_dict('records')\n",
    "            prompt = prepare_prompt(batch)\n",
    "            response = query_mistral(prompt)\n",
    "\n",
    "            if response and 'results' in response:\n",
    "                for j, item in enumerate(response['results'][:len(batch)]):\n",
    "                    idx = df.index[i + j]\n",
    "                    df.at[idx, 'IT'] = item.get('it_skill', False)\n",
    "                    df.at[idx, 'Mistral_check'] = item.get('correct_cluster', False)\n",
    "            else:\n",
    "                print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "            df.to_excel(output_path, index=False)\n",
    "\n",
    "            if i + BATCH_SIZE < len(df):\n",
    "                time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "        results[sheet_name] = df\n",
    "\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        for sheet_name, df in results.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/final_skills_mapping_Up_only_clasters.xlsx\"\n",
    "    output_file = \"data/verified_clusters.xlsx\"\n",
    "    verified_data = process_excel(input_file, output_file)\n",
    "    print(f\"\\n✅ Проверка завершена! Результаты сохранены в: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка листа: 4500 строк)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/180 [06:44<1:29:23, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 13/180 [07:39<1:20:32, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 29/180 [14:52<1:19:09, 31.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 31/180 [16:13<1:26:36, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 2): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 57/180 [32:04<1:10:24, 34.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 2): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 3): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "⚠️ Пропущен батч с 1425 по 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 60/180 [33:08<51:32, 25.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 2): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 3): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "⚠️ Пропущен батч с 1500 по 1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 61/180 [33:26<46:11, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n",
      "\n",
      "Ошибка (попытка 2): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 62/180 [34:14<1:00:22, 30.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 91/180 [50:20<46:08, 31.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 103/180 [59:05<1:08:25, 53.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 129/180 [1:14:03<35:41, 41.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): 429 Client Error: Too Many Requests for url: https://api.mistral.ai/v1/chat/completions\n",
      "Сырой ответ:\n",
      " {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"invalid_request_error\",\"param\":null,\"code\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [1:35:09<00:00, 31.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Проверка завершена! Результаты сохранены в: data/verified_canon_synonmyms_mc3_ms1.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Это код проверяет вториную  кластеризацию навыков HDBSCAN без шума\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"  \n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 25\n",
    "REQUEST_DELAY = 3\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты эксперт по IT-навыкам и кластеризации данных. Проверь корректность сопоставления IT-навыков:\n",
    "1. Канон (canon) — это эталонный навык\n",
    "2. Синоним (synonym) — предлагаемое соответствие\n",
    "\n",
    "Для каждой пары выполни два действия:\n",
    "1. Проверка: является ли canon IT-навыком (IT-сфера: программирование, инфраструктура, данные, кибербезопасность и т.д.)\n",
    "2. Проверка: является ли synonym корректным синонимом canon\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"it_skill\": true/false, \"correct_cluster\": true/false},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    pairs = \"\\n\".join([f\"{i+1}. Канон: {row['canon']} | Синоним: {row['synonym']}\" \n",
    "                      for i, row in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Проверь следующие пары:\\n{pairs}\\n\\nОтвет строго в формате JSON с ключом 'results':\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=950):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            \n",
    "            # Удаляем возможные обёртки ```json\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "            \n",
    "            # Попытка \"почистить\" JSON\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "            \n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def process_excel(file_path, output_path):\n",
    "    # Читаем только первый лист \n",
    "    df = pd.read_excel(file_path, sheet_name=0)  # sheet_name=0 - первый лист\n",
    "    \n",
    "    print(f\"\\nОбработка листа: {len(df)} строк)\")\n",
    "\n",
    "    df['IT'] = None\n",
    "    df['Mistral_check'] = None\n",
    "\n",
    "    for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "        batch = df.iloc[i:i+BATCH_SIZE].to_dict('records')\n",
    "        prompt = prepare_prompt(batch)\n",
    "        response = query_mistral(prompt)\n",
    "\n",
    "        if response and 'results' in response:\n",
    "            for j, item in enumerate(response['results'][:len(batch)]):\n",
    "                idx = df.index[i + j]\n",
    "                df.at[idx, 'IT'] = item.get('it_skill', False)\n",
    "                df.at[idx, 'Mistral_check'] = item.get('correct_cluster', False)\n",
    "        else:\n",
    "            print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "        # Сохраняем после каждого батча \n",
    "        df.to_excel(output_path, index=False)\n",
    "\n",
    "        if i + BATCH_SIZE < len(df):\n",
    "            time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "    # Сохраняем финальный результат\n",
    "    df.to_excel(output_path, index=False)\n",
    "    return df\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"data/canon_synonmyms_mc3_ms1.xlsx\"\n",
    "    output_file = \"data/verified_canon_synonmyms_mc3_ms1.xlsx\"\n",
    "    verified_data = process_excel(input_file, output_file)\n",
    "    print(f\"\\n✅ Проверка завершена! Результаты сохранены в: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54376c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): HTTPSConnectionPool(host='api.mistral.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000240E7FD7F10>: Failed to resolve 'api.mistral.ai' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Андрей\\AppData\\Local\\Temp\\ipykernel_9116\\349819032.py:99: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1–3 года' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'experience'] = item.get('experience', None)\n",
      " 23%|██▎       | 3/13 [01:07<03:46, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): ('Connection aborted.', ConnectionResetError(10054, 'Удаленный хост принудительно разорвал существующее подключение', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [03:32<00:00, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Извлечение завершено. Результаты сохранены в: df_to_ml_experience.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# exp\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"\n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 15\n",
    "REQUEST_DELAY = 5\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты помощник по извлечению опыта работы из вакансий. Для каждого текста определи, сколько у кандидата должен быть опыт работы, и заполни поле `experience` одним из следующих значений:\n",
    "\n",
    "- \"Нет опыта\"\n",
    "- \"1–3 года\"\n",
    "- \"3–6 лет\"\n",
    "- \"Более 6 лет\"\n",
    "\n",
    "Если информация об опыте не указана, поставь null.\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"experience\": \"Нет опыта\" / \"1–3 года\" / \"3–6 лет\" / \"Более 6 лет\" / null},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    entries = \"\\n\".join([f\"{i+1}. {text}\" for i, text in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Вот тексты вакансий:\\n{entries}\\n\\nОтвет строго в JSON по формату выше.\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=1024):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "\n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_experience(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    if 'experience' not in df.columns:\n",
    "        df['experience'] = None\n",
    "\n",
    "    texts = df['text'].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "        batch_texts = texts[i:i+BATCH_SIZE]\n",
    "        prompt = prepare_prompt(batch_texts)\n",
    "        response = query_mistral(prompt)\n",
    "\n",
    "        if response and 'results' in response:\n",
    "            for j, item in enumerate(response['results'][:len(batch_texts)]):\n",
    "                idx = i + j\n",
    "                df.at[idx, 'experience'] = item.get('experience', None)\n",
    "        else:\n",
    "            print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "        df.to_csv(input_file, index=False)\n",
    "\n",
    "        if i + BATCH_SIZE < len(df):\n",
    "            time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "    df.to_csv(input_file, index=False)\n",
    "    print(f\"\\n✅ Извлечение завершено. Результаты сохранены в: {input_file}\")\n",
    "    return df\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    extract_experience(\"df_to_ml_experience.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe9126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]C:\\Users\\Андрей\\AppData\\Local\\Temp\\ipykernel_15980\\3364430923.py:98: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Россия' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, 'country'] = item.get('country', None)\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Определение стран завершено. Результаты сохранены в: city_country_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# country \n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"\n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 30\n",
    "REQUEST_DELAY = 4\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты географический помощник. По каждому названию города определи страну, в которой он находится.\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"country\": \"Россия\"},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "Если город не удаётся распознать или страна неизвестна — верни null.\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    cities = \"\\n\".join([f\"{i+1}. {city}\" for i, city in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Определи страну для следующих городов:\\n{cities}\\n\\nОтвет строго в JSON по формату выше.\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=400):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "\n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_country(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    if 'country' not in df.columns:\n",
    "        df['country'] = None\n",
    "\n",
    "    # Берём только строки с непустыми city и пустыми country\n",
    "    mask = df['city'].notna() & (df['city'].astype(str).str.strip() != \"\") & df['country'].isna()\n",
    "    target_df = df[mask].copy()\n",
    "\n",
    "    cities = target_df['city'].astype(str).tolist()\n",
    "    index_list = target_df.index.tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(cities), BATCH_SIZE)):\n",
    "        batch_cities = cities[i:i+BATCH_SIZE]\n",
    "        batch_indices = index_list[i:i+BATCH_SIZE]\n",
    "        prompt = prepare_prompt(batch_cities)\n",
    "        response = query_mistral(prompt)\n",
    "\n",
    "        if response and 'results' in response:\n",
    "            for j, item in enumerate(response['results'][:len(batch_cities)]):\n",
    "                idx = batch_indices[j]\n",
    "                df.at[idx, 'country'] = item.get('country', None)\n",
    "        else:\n",
    "            print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "        df.to_csv(input_file, index=False)\n",
    "\n",
    "        if i + BATCH_SIZE < len(cities):\n",
    "            time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "    df.to_csv(input_file, index=False)\n",
    "    print(f\"\\n✅ Определение стран завершено. Результаты сохранены в: {input_file}\")\n",
    "    return df\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    extract_country(\"city_country_3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Загрузка текущего состояния файла...\n",
      "🔍 Найдено 118 городов без страны. Начинаем обработку...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:44<00:09,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ошибка (попытка 1): HTTPSConnectionPool(host='api.mistral.ai', port=443): Read timed out. (read timeout=120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:06<00:00, 31.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Обработка завершена. Файл сохранён: df_city_country.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# contry 2 с защитой \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_URL = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "API_KEY = \"\"\n",
    "MODEL_NAME = \"mistral-small-latest\"\n",
    "MAX_RETRIES = 3\n",
    "BATCH_SIZE = 20\n",
    "REQUEST_DELAY = 4\n",
    "INPUT_FILE = \"df_city_country.csv\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "INSTRUCTION = \"\"\"\n",
    "Ты географический помощник. По каждому названию города определи страну, в которой он находится.\n",
    "\n",
    "Ответ строго в формате JSON:\n",
    "{\n",
    "  \"results\": [\n",
    "    {\"country\": \"Россия\"},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\n",
    "Если город не удаётся распознать или страна неизвестна — верни null.\n",
    "\"\"\"\n",
    "\n",
    "def prepare_prompt(batch):\n",
    "    cities = \"\\n\".join([f\"{i+1}. {city}\" for i, city in enumerate(batch)])\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": INSTRUCTION},\n",
    "        {\"role\": \"user\", \"content\": f\"Определи страну для следующих городов:\\n{cities}\\n\\nОтвет строго в JSON по формату выше.\"}\n",
    "    ]\n",
    "\n",
    "def query_mistral(prompt, max_tokens=500):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                API_URL,\n",
    "                headers=HEADERS,\n",
    "                json={\n",
    "                    \"model\": MODEL_NAME,\n",
    "                    \"messages\": prompt,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": max_tokens,\n",
    "                    \"response_format\": {\"type\": \"json_object\"}\n",
    "                },\n",
    "                timeout=120\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "            if content.startswith(\"```json\"):\n",
    "                content = content[7:-3].strip()\n",
    "\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "            content = content.replace(\",}\", \"}\").replace(\",]\", \"]\")\n",
    "\n",
    "            return json.loads(content)\n",
    "\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"\\nОшибка (попытка {attempt+1}): {str(e)}\")\n",
    "            try:\n",
    "                print(\"Сырой ответ:\\n\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2 + random.random() * 3)\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_country(input_file):\n",
    "    print(\"🔄 Загрузка текущего состояния файла...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    if 'country' not in df.columns:\n",
    "        df['country'] = None\n",
    "\n",
    "    # Целевые строки: city непустой и country ещё не указан\n",
    "    mask = df['city'].notna() & (df['city'].astype(str).str.strip() != \"\") & df['country'].isna()\n",
    "    target_df = df[mask].copy()\n",
    "\n",
    "    cities = target_df['city'].astype(str).tolist()\n",
    "    index_list = target_df.index.tolist()\n",
    "\n",
    "    print(f\"🔍 Найдено {len(cities)} городов без страны. Начинаем обработку...\")\n",
    "\n",
    "    for i in tqdm(range(0, len(cities), BATCH_SIZE)):\n",
    "        # Загрузка последней версии файла (на случай падения)\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        batch_cities = cities[i:i + BATCH_SIZE]\n",
    "        batch_indices = index_list[i:i + BATCH_SIZE]\n",
    "\n",
    "        # Пропустить батч, если все страны уже определены\n",
    "        already_done = all(pd.notna(df.loc[idx, 'country']) for idx in batch_indices)\n",
    "        if already_done:\n",
    "            continue\n",
    "\n",
    "        prompt = prepare_prompt(batch_cities)\n",
    "        response = query_mistral(prompt)\n",
    "\n",
    "        if response and 'results' in response:\n",
    "            for j, item in enumerate(response['results'][:len(batch_cities)]):\n",
    "                idx = batch_indices[j]\n",
    "                df.at[idx, 'country'] = item.get('country', None)\n",
    "        else:\n",
    "            print(f\"⚠️ Пропущен батч с {i} по {i + BATCH_SIZE}\")\n",
    "\n",
    "        df.to_csv(input_file, index=False)\n",
    "\n",
    "        if i + BATCH_SIZE < len(cities):\n",
    "            time.sleep(REQUEST_DELAY + random.random())\n",
    "\n",
    "    print(f\"\\n✅ Обработка завершена. Файл сохранён: {input_file}\")\n",
    "    return df\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    extract_country(INPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba6376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
