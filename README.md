# Проект: Аналитика зарплат и вакансий IT
---

## Введение

Цель проекта — разработать инструмент, который позволяет оценивать диапазон заработной платы IT-специалистов на основе навыков, опыта и других параметров, а также давать рекомендации по улучшению резюме. Проект будет полезен тем, кто хочет понять, сколько стоит его профессиональный опыт на рынке, и как повысить свою конкурентоспособность.

## Технологии и инструменты

- **Язык и среды**: Python, Jupyter Notebook  
- **Библиотеки**: Pandas, NumPy, scikit-learn, HDBSCAN, KNN, RandomForestRegressor, CatBoost, Optuna, GridSearchCV  
- **LLM и NLP-инструменты**: использование модели Mistral (mistral-small-latest) для верификации навыков и сопоставления навыков-синонимов  
- **Работа с данными**: парсинг вакансий с hh.ru, Telegram-каналов и других источников; очистка, нормализация, маппинг навыков  
- **Процесс/архитектура**: сбор данных → EDA → кластеризация навыков → обучение регрессионной модели → оптимизация гиперпараметров → пайплайн → конечный вывод / рекомендации

### Оглавление

1. [Описание проекта](#disc)
2. [Основные цели](#w_case)
3. [Разработка модели для оценки стоимости IT-специалиста](#salary_predict)

    3.1. [Первичная обработка и анализ данных с hh.ru](#stage_1)

    3.2. [Кластеризация skills на каноны Сlovery (компания - организатор). LLM Checking](#stage_2_claster)

    3.3. [EDA данных с hh.ru. Модель с первыми результатами предсказания](#stage_2_eda+ML)

    3.4. [Пересборка данных с hh.ru c проверкой LLM. Полное EDA.](#stage_3_eda+LLM)

    3.5. [Пайплайн кластеризации вакансий](#vac_claster)

    3.6. [ML с улучшенной метрикой и подготовка данных для передачи бекэнду и фронту](#stage_3_ML)

    3.7. [Разработка мапинга position to skill (профессии) для альтернативных источников вакансий](#stage_4)

    3.8. [Сравнение метрик предсказания з/п на авторских position ](#stage_5_ml_OK_skills_pos)

    3.9. [Парсинг и получение данных из архивов Телеграм каналов](#tg_pars)

    3.10. [Разметка данных из телеграмм каналов и другмх сайтов. Получение position через LLM](#tg_LLM)

    3.11. [Очистка / первичная EDA вакансий из телеграмм каналов и другмх сайтов.](#stage_5_another_soursies_eda)

    3.12. [Прогон новых данных через пайплайн EDA hh.ru ](#stage_5_eda)

    3.13. [Мапинг Skills](#skills_mapping_LLM)

    3.14. [Повторная обработка с mapped_skills . Вторичный EDA. Кластеризация вакансий вокруг навыков. ML проверка реузльтатов](#stage_5_eda_ml)

    3.15. [Поиск оптимальных гиперпараметов CatBoost](#stage_5_ml3_catboost)

    3.16. [Финальный пайплайн для обработанных данных](stage_5_final_pipeline.ipynb)

4. [На входе резюме - на выходе рекомендации](#rec_cv)

    4.1. [Трансформация pdf в структурированные данные](#inference_cv)

    4.2. [Разработка промпта и тестирование получения ответов с рекомендациями](#rec_cv_stage)
5. [Результаты и метрики](#results)


### <a id ='disc'> 1. Описание проекта 

Бизнес-задачи: 
1. Разработать инструмент для оценки стоимости IT-специалиста на рынке труда на основе информации о вакансиях и навыков соискателя
2. Дать рекомендации по улучшению резюме для повышения привлекательности кандидата у HR

Технические задачи : 
1. Построить модель машинного обучения , которая на основе профессиональных характеристик соискателя определит актуальный диапазон заработной платы на рынке труда IT 
3. На основе собранных данных сделать fine-tuning LLM . На входе резюме - на выходе рекомендации.


### <a id ='w_case'> 2. Основные цели

- Собрать релевантные данные о вакансиях с hh.ru, Telegram-каналов и других источников  
- Структурировать и проверить данные, нормализовать навыки и вакансии  
- Провести разведывательный анализ (EDA) данных — найти закономерности, распределения, выбросы  
- Разработать методы кластеризации навыков и вакансий, чтобы упростить представление навыков  
- Обучить модель регрессии, определить оптимальные гиперпараметры  
- Подготовить пайплайн, пригодный для интеграции с фронтендом / бэкендом  
- Разработать компонент, который по резюме дает рекомендации по тому, как улучшить навыки, формат, подачу 

### <a id ='salary_predict'> 3. Разработка модель для оценки стоимости IT-специалиста

#### <a id ='stage_1'> 3.1 Первичная обработка и анализ данных с hh.ru

- На данном этапе загружено ~53 000 вакансий с hh.ru, проведён первичный анализ диапазона заработных плат по профессиям.

[ Смотреть ноутбук](stage_1_eda.ipynb)

#### <a id ='stage_2_claster'> 3.2 Кластеризация skills на каноны Сlovery (компания - организатор). LLM Checking

- Обработано около 15 000 уникальных навыков, разделённых на группы: русские, английские и смешанные.  
- Построены эмбединги, применён DBSCAN / HDBSCAN.  
- Промпты к LLM (Mistral) используются для проверки: смыслового соответствия синонимов канонам и определения, является ли навык IT-навыком.  

[Смотреть ноутбук c кластеризацией](stage_2_clean_and_clastering_skills_&_cloveri.ipynb)

[Смотреть ноутбук с промптами к LLM](LLM_Mistral_canon_synonym_check.ipynb)

#### <a id ='stage_2_eda+ML'> 3.3 EDA данных с hh.ru. Модель с первыми результатами предсказания

- Проведён EDA. Обучены базовые регрессионные модели, получены первые метрики качества. 
[Смотреть ноутбук](stage_2_eda_ml.ipynb)

- Обработка пропущенных значений (опыт, регион, навыки и др.) с помощью LLM-подходов.
[Смотреть ноутбук c обращениями к LLM](LLM_Mistral_API_labeling.ipynb)


#### <a id ='stage_3_eda+LLM'> 3.4 Пересборка данных с hh.ru c проверкой LLM. Полное EDA.

- Проведены дополнительные исследования данных с hh.ru, выявлено около 50 % несоответсвия текста резюме и данных в разметке
- Выполнена доразметка вакансий с hh.ru через LLM, обновлены навыки и профессии.  
- Полный анализ данных: статистики, распределения, зависимости. 
 [Смотреть ноутбук](stage_3_eda.ipynb)

#### <a id ='vac_claster'> 3.5 Пайплайн кластеризации вакансий.

- Кластеризация вакансий с использованием HDBSCAN и дополнительной проверкой через LLM. 
[Смотреть ноутбук](stage_3_vac_claster_line_2.ipynb)

#### <a id ='stage_3_ML'> 3.6 ML с улучшенной метрикой и подготовка данных для передачи бекэнду и фронту.

- Подобраны оптимальные входные параметры, обучен Random Forest
- Лучшие на данном этапе показатели метрики: MAE = 21 694.42, R² = 0.74.
[Смотреть ноутбук](stage_3_ml.ipynb)

#### <a id ='stage_4'> 3.7 Разработка маппинга position to skill (профессии к навыку) для альтернативных источников вакансий.

- Проработали вариант создания новых position (профессий) для маппинга вакансий , которые будем собирать через альтернативные источники .   
[Смотреть ноутбук](stage_4.ipynb)

#### <a id ='stage_5_ml_OK_skills_pos'> 3.8 Сравнение метрик предсказания з/п на авторских position (профессий).

 - Сравнили результаты метрик ML для разработанных профессий.  
[Смотреть ноутбук](stage_5_ml_OK_skills_pos.ipynb)

#### <a id ='tg_pars'> 3.9 Парсинг и получение данных из архивов Телеграм каналов.

[Смотреть ноутбук](stage_5_tg_parsing.ipynb)

#### <a id ='tg_LLM'> 3.10 Разметка данных из телеграмм каналов и других сайтов. Получение position (професии) через LLM.

- Разработка промпта для получения профессии (position) для вакансий из альтернативных источников.  
[Смотреть ноутбук](tg_LLM_labeling.ipynb)

#### <a id ='stage_5_another_soursies_eda'> 3.11 Очистка и первичная EDA вакансий из телеграмм каналов.

[Смотреть ноутбук](stage_5_another_soursies_eda.ipynb)


#### <a id ='stage_5_eda'> 3.12 Прогон новых данных через пайплайн EDA.

[Смотреть ноутбук](stage_5_eda.ipynb)

#### <a id ='skills_mapping_LLM'> 3.13 Мапинг Skills.

***Результаты кластеризации skills на предыдущих этапах были признаны неудовлетворительными, так как не давали прироста на метриках, а чаще даже ухудшали их.***

- Разработали пайплайн , который не только определяет каноны навыков по каждой профессии, но и ищет синонимы по всей профессии.

 [Смотреть ноутбук](skills_mapping_LLM.ipynb)

#### <a id ='stage_5_eda'> 3.14 Повторная обработка с mapped_skills . Вторичный EDA. Кластеризация вакансий вокруг навыков. ML проверка результатов.

- Сделана кластеризация вакансий "вокруг скилов" 
- Проведена дополнительная кластеризация навыков через KNN, а так же дополнительное исследование грэйда и опыта специалиста относительно з/п. 
- Сократили размерности по skills c 42 000 уникальных навыков до ~ 2000 , а разноообразие вакансий с 8000 до ~3000 
- Получили более качественные показатели метрики **MAE = 15 715.60 , R² = 0.74** .
[Смотреть ноутбук](stage_5_eda_ml.ipynb)

#### <a id ='stage_5_ml3_catboost'> 3.15 Поиск оптимальных гиперпараметов CatBoost. 
[Смотреть ноутбук](stage_5_ml3_catboost.ipynb)

#### 3.16 Финальный пайплайн для обработанных данных. 
 [Смотреть ноутбук](stage_5_final_pipeline.ipynb)

*** Финальная функция предсказания з/п для контейнера бекэнда и фронта.  [Смотреть пайтон скрипт](stage_6_prepare.ipynb)

*** [Joblibs и энкодеры в папке](/to_Deploy/)



### <a id ='rec_cv'> 4. На входе резюме - на выходе рекомендации



#### <a id ='inference_cv'> 4.1 Трансформация pdf в структурированные данные

- Трансформация PDF / DOC в структурированные данные. 
[Папка с файлами этапа](/Inference_cv/)

#### <a id ='rec_cv_stage'> 4.2 Разработка промпта и тестирование получения ответов с рекомендациями

- Разработка и тестирование промптов и логики выдачи рекомендаций по резюме. 
[Папка с файлами этапа](/rec_cv/)


### <a id ='results'> 5. Результаты и метрики

- Снижение количества уникальных навыков с ~42 000 до ~2 000, что повысило стабильность модели  
- Сокращение числа категорий вакансий с ~8 000 до ~3 000  
- Улучшенные метрики модели: **MAE = 15 715.60 , R² = 0.74** 
- Пилотные рекомендации по резюме показали, что корректировка навыков и форматирования даёт лучшие отклики со стороны HR (на основе фидбэка)

