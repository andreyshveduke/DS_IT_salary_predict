{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508464d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "from ast import literal_eval\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# Конфиг\n",
    "# -----------------------------\n",
    "ARTIFACT_DIR = os.environ.get(\"ARTIFACT_DIR\", \"to_Deploy\")\n",
    "JOBLIB_DIR = os.path.join(ARTIFACT_DIR, \"joblib\")\n",
    "TOP_SKILLS_N = 30\n",
    "TEST_SIZE = 0.20\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Параметры CatBoost (подобранные через Optuna)\n",
    "\n",
    "CAT_PARAMS_NO_VAC ={'iterations': 956,\n",
    "                    'learning_rate': 0.02732361681926645, \n",
    "                    'depth': 10, \n",
    "                    'l2_leaf_reg': 7.899511609358967, \n",
    "                    'random_strength': 7.937743579871258, \n",
    "                    'bagging_temperature': 0.07856525216914066,\n",
    "                    'border_count': 135,\n",
    "                    'min_data_in_leaf': 48, \n",
    "                    'grow_policy': 'Lossguide',\n",
    "                    'random_seed': RANDOM_STATE,\n",
    "                    'verbose': 100\n",
    "                    }\n",
    "\n",
    "# -----------------------------\n",
    "# Утилиты\n",
    "# -----------------------------\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "    os.makedirs(JOBLIB_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def safe_literal_eval(x):\n",
    "    \"\"\"Безопасное преобразование строки в список.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif isinstance(x, str):\n",
    "        try:\n",
    "            return literal_eval(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def filtered_skills_top_n(df_in: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Оставляем только топ-n самых частых mapped_skills внутри каждой позиции.\"\"\"\n",
    "    df = df_in.copy()\n",
    "    if 'mapped_skills' not in df.columns:\n",
    "        raise KeyError(\"mapped_skills column is required\")\n",
    "    for pos in df['position'].dropna().unique():\n",
    "        mask = df['position'] == pos\n",
    "        skills_lists = df.loc[mask, 'mapped_skills']\n",
    "        all_skills = [s for lst in skills_lists for s in (lst or [])]\n",
    "        cnt = Counter(all_skills)\n",
    "        top = set([s for s, _ in cnt.most_common(n)])\n",
    "        df.loc[mask, 'mapped_skills'] = skills_lists.apply(lambda lst: [s for s in (lst or []) if s in top])\n",
    "    return df\n",
    "\n",
    "# Функция очистки и нормализации\n",
    "def process_series(series, colname, position):\n",
    "    series = pd.to_numeric(series, errors='coerce')\n",
    "    series = series.dropna()\n",
    "    n_total = len(series)\n",
    "    if len(series) < 20:\n",
    "        return series\n",
    "\n",
    "    stat, p = normaltest(series)\n",
    "    is_normal = p > 0.05\n",
    "\n",
    "    if is_normal:\n",
    "        mu, sigma = series.mean(), series.std()\n",
    "        mask = (series >= mu - 3 * sigma) & (series <= mu + 3 * sigma)\n",
    "    else:\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        mask = (series >= q1 - 1.5 * iqr) & (series <= q3 + 1.5 * iqr)\n",
    "\n",
    "    n_filtered = mask.sum()\n",
    "    n_removed = n_total - n_filtered\n",
    "\n",
    "\n",
    "    return series[mask]\n",
    "\n",
    "\n",
    "def clean_targets_by_position(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Очистка и нормализация таргетов salary по позициям.\"\"\"\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # Создаем новые колонки для нормализованных значений\n",
    "    df['salary_from_norm'] = np.nan\n",
    "    df['salary_to_norm'] = np.nan\n",
    "    \n",
    "    positions = df['position'].dropna().unique()\n",
    "    \n",
    "    if 'salary from' in df.columns:\n",
    "        for pos in positions:\n",
    "            m = df['position'] == pos\n",
    "            s = process_series(df.loc[m, 'salary from'], 'salary from', pos)\n",
    "            if s is not None and len(s) > 0:\n",
    "                df.loc[s.index, 'salary_from_norm'] = s\n",
    "    \n",
    "    if 'salary to' in df.columns:\n",
    "        for pos in positions:\n",
    "            m = df['position'] == pos\n",
    "            s = process_series(df.loc[m, 'salary to'], 'salary to', pos)\n",
    "            if s is not None and len(s) > 0:\n",
    "                df.loc[s.index, 'salary_to_norm'] = s\n",
    "    \n",
    "    # Оставляем только строки, где есть хотя бы одна нормализованная зарплата\n",
    "    has_from = df['salary_from_norm'].notna()\n",
    "    has_to = df['salary_to_norm'].notna()\n",
    "    df = df[has_from | has_to].copy()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Создание финальных признаков (порядковое кодирование).\"\"\"\n",
    "    experience_order = {\n",
    "        'Нет опыта': 0,\n",
    "        '1–3 года': 1,\n",
    "        '3–6 лет': 2,\n",
    "        'Более 6 лет': 3,\n",
    "        'Unknown': -1\n",
    "    }\n",
    "    level_order = {\n",
    "        'Trainee': 0,\n",
    "        'Junior': 1,\n",
    "        'Middle': 2,\n",
    "        'Senior': 3,\n",
    "        'Lead': 4,\n",
    "        'Chief': 5,\n",
    "        'Unknown': -1\n",
    "    }\n",
    "    df['experience_ord'] = df['experience'].map(experience_order).fillna(-1).astype(int)\n",
    "    df['level_ord'] = df['level'].map(level_order).fillna(-1).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_encoders(df: pd.DataFrame) -> Tuple[OneHotEncoder, MultiLabelBinarizer]:\n",
    "    \"\"\"Фитим OHE для категориальных (без experience и level) и MLB для mapped_skills.\"\"\"\n",
    "    cat_cols = ['position', 'schedule', 'employment', 'region']\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    ohe.fit(df[cat_cols])\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(df['mapped_skills'])\n",
    "    return ohe, mlb\n",
    "\n",
    "def build_encoders_2(df: pd.DataFrame) -> Tuple[OneHotEncoder, MultiLabelBinarizer]:\n",
    "    \"\"\"Фитим OHE для категориальных (c experience и level) и MLB для mapped_skills.\"\"\"\n",
    "    cat_cols = ['position', 'schedule', 'employment', 'region', 'experience_ord', 'level_ord']\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    ohe.fit(df[cat_cols])\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(df['mapped_skills'])\n",
    "    return ohe, mlb\n",
    "\n",
    "\n",
    "def transform_features(df: pd.DataFrame, ohe: OneHotEncoder, mlb: MultiLabelBinarizer) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"Преобразование признаков в матрицу (OHE + ord + MLB).\"\"\"\n",
    "    cat_cols = ['position', 'schedule', 'employment', 'region']\n",
    "    ord_cols = ['experience_ord', 'level_ord']\n",
    "    X_ohe = ohe.transform(df[cat_cols])\n",
    "    X_ord = df[ord_cols].values\n",
    "    X_mlb = mlb.transform(df['mapped_skills'])\n",
    "    #X = np.hstack([X_ohe, X_mlb])\n",
    "    X = np.hstack([X_ohe, X_ord, X_mlb])\n",
    "    #feature_names = list(ohe.get_feature_names_out(cat_cols)) + list(mlb.classes_)\n",
    "    feature_names = list(ohe.get_feature_names_out(cat_cols)) + ord_cols + list(mlb.classes_)\n",
    "    return X, X_mlb, feature_names\n",
    "\n",
    "\n",
    "def stratified_split(X: np.ndarray, y: pd.Series, df_positions: pd.Series, test_size: float = TEST_SIZE):\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=RANDOM_STATE)\n",
    "    for tr_idx, te_idx in splitter.split(X, df_positions):\n",
    "        return tr_idx, te_idx\n",
    "    raise RuntimeError(\"Ошибка разбиения выборки\")\n",
    "\n",
    "\n",
    "def train_cb(X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray) -> CatBoostRegressor:\n",
    "    \"\"\"Обучение модели CatBoost.\"\"\"\n",
    "    # Убедимся, что нет NaN в целевой переменной\n",
    "    mask_train = ~np.isnan(y_train)\n",
    "    mask_val = ~np.isnan(y_val)\n",
    "    \n",
    "    X_train_clean = X_train[mask_train]\n",
    "    y_train_clean = y_train[mask_train]\n",
    "    X_val_clean = X_val[mask_val]\n",
    "    y_val_clean = y_val[mask_val]\n",
    "    \n",
    "    model = CatBoostRegressor(task_type='GPU',**CAT_PARAMS_NO_VAC)\n",
    "    model.fit(\n",
    "        X_train_clean,\n",
    "        y_train_clean,\n",
    "        eval_set=(X_val_clean, y_val_clean),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=100,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model: CatBoostRegressor, X_test: np.ndarray, y_test: np.ndarray, tag: str = \"\") -> Dict[str, float]:\n",
    "    \"\"\"Оценка качества модели.\"\"\"\n",
    "    # Убедимся, что нет NaN в тестовых данных\n",
    "    mask = ~np.isnan(y_test)\n",
    "    if mask.sum() == 0:\n",
    "        return {\"tag\": tag, \"MAE\": float('nan'), \"R2\": float('nan'), \"MAPE\": float('nan')}\n",
    "    \n",
    "    X_test_clean = X_test[mask]\n",
    "    y_test_clean = y_test[mask]\n",
    "    \n",
    "    y_pred = model.predict(X_test_clean)\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"MAE\": float(mean_absolute_error(y_test_clean, y_pred)),\n",
    "        \"R2\": float(r2_score(y_test_clean, y_pred)),\n",
    "        \"MAPE\": float(mean_absolute_percentage_error(y_test_clean, y_pred)),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def save_top_skills_by_position(model, mlb, df, filename=\"top_skills_by_position.json\", top_n=30):\n",
    "    \"\"\"Сохраняем топ-N скиллов по каждой позиции.\"\"\"\n",
    "    feature_importances = model.get_feature_importance(type=\"FeatureImportance\")\n",
    "    feature_names = model.feature_names_\n",
    "\n",
    "\n",
    "    skills_importances = {name: imp for name, imp in zip(feature_names, feature_importances) if name in mlb.classes_}\n",
    "    skills_sorted = sorted(skills_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    result = {}\n",
    "    for pos in df['position'].unique():\n",
    "        result[pos] = [skill for skill, _ in skills_sorted[:top_n]]\n",
    "\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def save_manifest(ohe, mlb, filename=\"columns_manifest.json\"):\n",
    "    \"\"\"Сохраняем описание порядка признаков.\"\"\"\n",
    "    manifest = {\n",
    "    \"categorical_features\": list(ohe.get_feature_names_out()),\n",
    "    \"ordinal_features\": [\"experience_ord\", \"level_ord\"],\n",
    "    \"skills_features\": list(mlb.classes_),\n",
    "    \"description\": \"Порядок признаков: сначала категориальные (OHE), затем порядковые (experience_ord, level_ord), затем бинаризация skills\"\n",
    "    }\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "def save_filter_options(df: pd.DataFrame, filename=\"filter_options.json\"):\n",
    "    \"\"\"Сохраняем доступные фильтры для фронта из реальных данных.\"\"\"\n",
    "    # Берем уникальные значения из данных, исключая NaN\n",
    "    options = {\n",
    "        \"experience\": sorted(df['experience'].dropna().unique().tolist()),\n",
    "        \"schedule\": sorted(df['schedule'].dropna().unique().tolist()),\n",
    "        \"employment\": sorted(df['employment'].dropna().unique().tolist()),\n",
    "        \"level\": sorted(df['level'].dropna().unique().tolist()),\n",
    "        \"region\": sorted(df['region'].dropna().unique().tolist()),\n",
    "        \"position\": sorted(df['position'].dropna().unique().tolist())\n",
    "    }\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(options, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "def save_top_skills_by_position_separate_models(df: pd.DataFrame, filename: str, top_n: int = 30):\n",
    "    \"\"\"Сохраняем топ-N скиллов по каждой позиции, обучая отдельные модели.\"\"\"\n",
    "    \n",
    "    # Основные категориальные признаки (без position, так как мы уже фильтруем по ней)\n",
    "    cat_features = ['experience', 'schedule', 'employment', 'level', 'region']\n",
    "    skill_feature = 'mapped_skills'\n",
    "    \n",
    "    # Словарь для хранения топ-скиллов\n",
    "    top_skills_per_position = defaultdict(list)\n",
    "    \n",
    "    for pos in tqdm(df['position'].unique(), desc=\"Processing positions\"):\n",
    "        try:\n",
    "            # Фильтруем данные по позиции\n",
    "            df_pos = df[df['position'] == pos].copy()\n",
    "            \n",
    "            if len(df_pos) < 30:  # Минимальное количество samples для обучения\n",
    "                print(f\"⚠️  Пропускаем позицию {pos}: слишком мало данных ({len(df_pos)})\")\n",
    "                continue\n",
    "            \n",
    "            # Признаки и цель (используем нормализованную зарплату)\n",
    "            X = df_pos[cat_features + [skill_feature]]\n",
    "            y = df_pos['salary_from_norm']\n",
    "            \n",
    "            # Удаляем строки с NaN в целевой переменной\n",
    "            valid_mask = ~y.isna()\n",
    "            X = X[valid_mask]\n",
    "            y = y[valid_mask]\n",
    "            \n",
    "            if len(X) < 20:  # Проверяем после фильтрации\n",
    "                print(f\"⚠️  Пропускаем позицию {pos}: мало данных после фильтрации ({len(X)})\")\n",
    "                continue\n",
    "            \n",
    "            # Кодирование\n",
    "            ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            \n",
    "            # Кодируем категориальные признаки\n",
    "            X_cat_encoded = ohe.fit_transform(X[cat_features])\n",
    "            \n",
    "            # Кодируем скиллы\n",
    "            X_skills_encoded = mlb.fit_transform(X[skill_feature])\n",
    "            \n",
    "            # Объединяем признаки\n",
    "            X_final = np.hstack([X_cat_encoded, X_skills_encoded])\n",
    "            \n",
    "            # Разделение на train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_final, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "            )\n",
    "            \n",
    "            # Параметры CatBoost для отдельных моделей\n",
    "            catboost_params = {\n",
    "                'iterations': 500,\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 3,\n",
    "                'random_strength': 1,\n",
    "                'verbose': False,\n",
    "                'random_seed': RANDOM_STATE\n",
    "            }\n",
    "            \n",
    "            # Обучение CatBoost\n",
    "            model = CatBoostRegressor(**catboost_params)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Получаем важности признаков\n",
    "            importances = model.get_feature_importance()\n",
    "            \n",
    "            # Список всех признаков\n",
    "            ohe_features = ohe.get_feature_names_out(cat_features)\n",
    "            skill_features = mlb.classes_\n",
    "            all_feature_names = list(ohe_features) + list(skill_features)\n",
    "            \n",
    "            # Создаем DataFrame с важностями\n",
    "            feat_df = pd.DataFrame({\n",
    "                'feature': all_feature_names,\n",
    "                'importance': importances\n",
    "            })\n",
    "            \n",
    "            # Отбираем только скиллы\n",
    "            skill_df = feat_df[feat_df['feature'].isin(skill_features)]\n",
    "            top_skills = skill_df.sort_values(by='importance', ascending=False)\n",
    "            \n",
    "            # Сохраняем топ-скиллы\n",
    "            top_skills_per_position[pos] = top_skills['feature'].head(top_n).tolist()\n",
    "            \n",
    "            print(f\"✅ Позиция {pos}: обработано {len(X)} samples, найдено {len(top_skills)} скиллов\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при обработке позиции {pos}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Сохраняем в JSON\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(top_skills_per_position, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return top_skills_per_position\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Основной пайплайн обучения\n",
    "# -----------------------------\n",
    "\n",
    "def run_training(df: pd.DataFrame) -> Dict[str, Dict[str, float]]:\n",
    "    ensure_dirs()\n",
    "\n",
    "    # 1) Преобразуем mapped_skills в список\n",
    "    df['mapped_skills'] = df['mapped_skills'].apply(safe_literal_eval)\n",
    "    \n",
    "    allowed_positions = [\n",
    "    \"Аналитик\",\n",
    "    \"Бизнес-аналитик\",\n",
    "    \"Дизайнер, художник\",\n",
    "    \"Продуктовый аналитик\",\n",
    "    \"Руководитель проектов\",\n",
    "    \"Сетевой инженер\",\n",
    "    \"Системный администратор\",\n",
    "    \"Специалист по информационной безопасности\",\n",
    "    \"Специалист технической поддержки\",\n",
    "    \"Технический писатель\"\n",
    "]\n",
    "    \n",
    "    df = df[df['position'].isin(allowed_positions)]\n",
    "\n",
    "    # 2) Оставляем только топ-30 скиллов в каждой позиции\n",
    "    df1 = filtered_skills_top_n(df, TOP_SKILLS_N)\n",
    "    df1 = df1[df1['mapped_skills'].apply(lambda x: isinstance(x, list) and len(x) > 0)].copy()\n",
    "\n",
    "    # 3) Очистка таргетов по позициям\n",
    "    df2 = clean_targets_by_position(df1)\n",
    "\n",
    "    # 4) Добавляем порядковые признаки experience_ord и level_ord\n",
    "    df2 = create_features(df2)\n",
    "\n",
    "    # 5) Фитим энкодеры\n",
    "    ohe, mlb = build_encoders(df2)\n",
    "\n",
    "    # 6) Преобразуем признаки\n",
    "    X_all, X_skills, feature_names = transform_features(df2, ohe, mlb)\n",
    "\n",
    "     # 7) Разбиваем на train/test (стратификация по position)\n",
    "    tr_idx, te_idx = stratified_split(X_all, df2['salary_from_norm'], df2['position'])\n",
    "\n",
    "    artifacts = {}\n",
    "\n",
    "    # Обучение salary_from\n",
    "    y_from = df2['salary_from_norm'].values\n",
    "    model_from = train_cb(X_all[tr_idx], y_from[tr_idx], X_all[te_idx], y_from[te_idx])\n",
    "    metrics_from = evaluate(model_from, X_all[te_idx], y_from[te_idx], tag='salary_from')\n",
    "    artifacts['salary_from'] = metrics_from\n",
    "\n",
    "    # Обучение salary_to\n",
    "    y_to = df2['salary_to_norm'].values\n",
    "    valid_to = ~pd.isna(y_to)\n",
    "    tr_to = np.intersect1d(np.where(valid_to)[0], tr_idx)\n",
    "    te_to = np.intersect1d(np.where(valid_to)[0], te_idx)\n",
    "\n",
    "    model_to = train_cb(X_all[tr_to], y_to[tr_to], X_all[te_to], y_to[te_to])\n",
    "    metrics_to = evaluate(model_to, X_all[te_to], y_to[te_to], tag='salary_to')\n",
    "    artifacts['salary_to'] = metrics_to\n",
    "\n",
    "    # Сохраняем модели и энкодеры\n",
    "    joblib.dump(model_from, os.path.join(JOBLIB_DIR, 'cb_model_from.joblib'))\n",
    "    joblib.dump(model_to,   os.path.join(JOBLIB_DIR, 'cb_model_to.joblib'))\n",
    "    joblib.dump(ohe,        os.path.join(JOBLIB_DIR, 'ohe_encoder.joblib'))\n",
    "    joblib.dump(mlb,        os.path.join(JOBLIB_DIR, 'mlb_encoder.joblib'))\n",
    "    \n",
    "    # Сохраняем топ скиллы по позициям и манифест\n",
    "    #save_top_skills_by_position(model_from, mlb, df2, filename=f\"{ARTIFACT_DIR}/top_skills_by_position.json\", top_n=30)\n",
    "    top_skills = save_top_skills_by_position_separate_models(\n",
    "        df2, \n",
    "        filename=os.path.join(ARTIFACT_DIR, \"top_skills_by_position.json\"), \n",
    "        top_n=30\n",
    "    )\n",
    "    \n",
    "    save_manifest(ohe, mlb, filename= os.path.join(ARTIFACT_DIR, \"columns_manifest.json\"))\n",
    "    save_filter_options(df2, filename=os.path.join(ARTIFACT_DIR, 'filter_options.json'))\n",
    "\n",
    "    return artifacts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "953e8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_result = pd.read_csv('data/df_train_result_from_eda_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fedf352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_result['mapped_skills'] = df_train_result['mapped_skills'].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "18b7d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "skill_mapping = {\n",
    "    \"Дизайнер, художник\": {\n",
    "        \"PHOTOSHOP\": \"Adobe Photoshop\",\n",
    "        \"MS Office Word, Excel, Power Point, Outlook\": \"Microsoft Office Word, Excel\",\n",
    "        \"знание программы CorelDRAW\":\"CorelDRAW\",\n",
    "        \"COREL\":\"CorelDRAW\",\n",
    "        \"Adobe Creative Suite Photoshop, Illustrator, InDesign, After Effects\": \"Adobe Creative Suite\",\n",
    "        \"Adobe Creative Cloud: Photoshop, Illustrator, InDesign, After Effects, Power Point\": \"Adobe Creative Cloud\",\n",
    "        \"2д анимация в Adobe After Effects\":\"2D анимация Adobe After Effects\",\n",
    "        \"Adobe\": \"Adobe Creative Suite\",\n",
    "        \"3d\": \"3D визуализация\",\n",
    "        \"HTML/CSS/JS базовый уровень\":\"HTML/CSS/JS\"\n",
    "    },\n",
    "    \"Аналитик\": {\n",
    "        \"Знание предметной области бухгалтерский и налоговый учет\": \"Бухгалтерский, оперативный и фин. учет\",\n",
    "        \"1С:Управление торговлей\":\"1С:УТ\",\n",
    "        \"MS Word\": \"MS Office\",\n",
    "        \"MS Outlook\": \"MS Office\",\n",
    "        \"Технические задания\":\"Составление ТЗ\"\n",
    "    },\n",
    "    \"Руководитель проектов\":{\n",
    "        \"1С системы продажи, закупки, производство, выполнение работ\": \"1C\",\n",
    "        \"MS Office Word\": \"MS Office\",\n",
    "        \"MS Office Outlook\": \"MS Office\",\n",
    "        \"MS Office Excel\": \"MS Office\",\n",
    "        \"BPMN 2.0\":\"BPMN\",\n",
    "        \"MS Office Outlook\":\"MS Office\"\n",
    "    },\n",
    "    \"Менеджер продукта\": {\n",
    "        \"Google Analytics\": \"GA\"\n",
    "    },\n",
    "    \"Методолог\": {\n",
    "        \"уверенный пользователь ПК MS Office, Outlook, уверенное владение Excel\": \"Уверенный пользователь ПК (MS Office, Outlook Excel)\",\n",
    "        \"опыт работы в учетных бухгалтерских системах SAP, 1C и других\": \"Опыт работы в Бух системах SAP, 1C и др\"\n",
    "    },\n",
    "    \"Программист, разработчик\": {\n",
    "        \"1С: Бухгалтерия 3\": \"1С\",\n",
    "        \"1c8\": \"1С\"\n",
    "    },\n",
    "    \"Продуктовый аналитик\": {\n",
    "        \"Excel/Google Sheets\": \"Google Sheets\"\n",
    "    },\n",
    "    \"Системный администратор\": {\n",
    "        \"Windows Server\": \"Microsoft Windows Server\",\n",
    "        \"Windows\": \"Microsoft Windows\",\n",
    "        \"Microsoft Office\": \"MS Office\",\n",
    "        \"Active Directory\": \"MS ActiveDirectory\",\n",
    "        \"Администрирование серверного оборудования под управлением ОС MS Windows Server 2008-2016 и OС Linux\": \"Microsoft Windows Server/Linux\",\n",
    "        \"MS Office Word\": \"MS Office\"\n",
    "        \n",
    "    },\n",
    "    \"Специалист по информационной безопасности\": {\n",
    "        \"Windows/Linux\": \"Linux/Windows\",\n",
    "        \"Windows Server\": \"Microsoft Windows Server\"\n",
    "    },\n",
    "    \"Специалист технической поддержки\": {\n",
    "        \"работа в офисных программах и CRM\": \"CRM\",\n",
    "        \"AD\": \"Active Directory\",\n",
    "        \"Service/Help Desk\": \"HelpDesk/ServiceDesk\",\n",
    "        \"MS Office Word\": \"MS Office\",\n",
    "        \"Консультирование клиентов по продуктам \\\"1С\": \"Консультирование клиентов по продуктам 1С\",\n",
    "        \"Командная строка windows\":\"CMD/PowerShell\",\n",
    "        \"JIRA\": \"Jira\"\n",
    "    },\n",
    "    \"Сетевой инженер\":{\n",
    "        \"стека протоколов TCP/IP\": \"Стек протоколов TCP/IP\",\n",
    "        \"Сетевая модель OSI и модель TCP/IP\":\"OSI / TCP/IP\",\n",
    "        \"сетевые протоколы и технологии L2/L3\": \"Протоколы и технологии L2/L3\",\n",
    "        \"мониторинг работы сетевых устройств Eltex, Cisco\": \"Мониторинг работы сетевых устройств Eltex, Cisco\",\n",
    "        \"Настройка и поддержка сетевого оборудования d-link, mikrotik, cisco, juniper\": \"Настройка и поддержка сетевого оборудования D-link, Mikrotik, Cisco, Juniper, Huawei\",\n",
    "        \"Сетевое оборудование коммутаторы, маршрутизаторы\": \"Настройка и поддержка сетевого оборудования D-link, Mikrotik, Cisco, Juniper, Huawei\",\n",
    "        \"IP\":\"Стек протоколов TCP/IP\",\n",
    "        \"Работа с оборудованием вендоров Cisco, Juniper, Huawei\": \"Настройка и поддержка сетевого оборудования D-link, Mikrotik, Cisco, Juniper, Huawei\",\n",
    "        \"Протоколы и технологии\": \"Протоколы и технологии L2/L3\"\n",
    "    },\n",
    "    \"Технический писатель\":{\n",
    "        \"Microsoft Outlook\": \"MS Office\",\n",
    "        \"Microsoft Word\": \"MS Office\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def apply_position_mapping(row, mapping):\n",
    "    position = row['position']\n",
    "    skills = row['mapped_skills']\n",
    "\n",
    "    if not isinstance(skills, list):\n",
    "        return skills  # на всякий случай защита от кривых данных\n",
    "\n",
    "    if position in mapping:\n",
    "        mapped = [mapping[position].get(skill, skill) for skill in skills]\n",
    "        # убираем дубликаты, но сохраняем порядок\n",
    "        mapped = list(OrderedDict.fromkeys(mapped))\n",
    "        return mapped\n",
    "    \n",
    "    return skills\n",
    "\n",
    "\n",
    "df_train_result['mapped_skills'] = df_train_result.apply(\n",
    "    lambda row: apply_position_mapping(row, skill_mapping),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f73eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено строк: 4\n",
      "Осталось строк: 17394\n"
     ]
    }
   ],
   "source": [
    "# Функция для обработки списка скилов\n",
    "def process_skills_list(skills_list):\n",
    "    if not isinstance(skills_list, list):\n",
    "        return skills_list\n",
    "    \n",
    "    # Удаляем 'anchor/Other' из списка\n",
    "    filtered_skills = [skill for skill in skills_list if skill != 'anchor/Other']\n",
    "    \n",
    "    # Если список стал пустым после фильтрации, возвращаем None\n",
    "    return filtered_skills if filtered_skills else None\n",
    "\n",
    "# Применяем функцию к столбцу mapped_skills\n",
    "df_train_result['mapped_skills'] = df_train_result['mapped_skills'].apply(process_skills_list)\n",
    "\n",
    "# Удаляем строки, где mapped_skills is None (пустой список после удаления 'anchor/Other')\n",
    "initial_count = len(df_train_result)\n",
    "df_train_result = df_train_result[df_train_result['mapped_skills'].notna()]\n",
    "final_count = len(df_train_result)\n",
    "\n",
    "print(f\"Удалено строк: {initial_count - final_count}\")\n",
    "print(f\"Осталось строк: {final_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e52517ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 44430.0830276\ttest: 45827.3133112\tbest: 45827.3133112 (0)\ttotal: 14ms\tremaining: 13.4s\n",
      "100:\tlearn: 22453.9290102\ttest: 22874.3518030\tbest: 22874.3518030 (100)\ttotal: 1.28s\tremaining: 10.9s\n",
      "200:\tlearn: 21195.4562392\ttest: 22077.2797190\tbest: 22077.2797190 (200)\ttotal: 2.38s\tremaining: 8.95s\n",
      "300:\tlearn: 20792.5442004\ttest: 21963.8292895\tbest: 21963.8292895 (300)\ttotal: 3.22s\tremaining: 7.01s\n",
      "400:\tlearn: 20478.5914690\ttest: 21922.9659882\tbest: 21921.3915392 (398)\ttotal: 4.08s\tremaining: 5.64s\n",
      "500:\tlearn: 20219.3586103\ttest: 21927.8770926\tbest: 21915.7464116 (406)\ttotal: 4.9s\tremaining: 4.45s\n",
      "bestTest = 21915.74641\n",
      "bestIteration = 406\n",
      "Shrink model to first 407 iterations.\n",
      "0:\tlearn: 49610.6398702\ttest: 49662.2902951\tbest: 49662.2902951 (0)\ttotal: 13.8ms\tremaining: 13.2s\n",
      "100:\tlearn: 27309.8951123\ttest: 27853.4887316\tbest: 27853.4887316 (100)\ttotal: 1.36s\tremaining: 11.5s\n",
      "200:\tlearn: 25657.1370888\ttest: 26980.5480560\tbest: 26980.5480560 (200)\ttotal: 2.45s\tremaining: 9.2s\n",
      "300:\tlearn: 25110.1505237\ttest: 26842.6221762\tbest: 26842.6221762 (300)\ttotal: 3.47s\tremaining: 7.55s\n",
      "400:\tlearn: 24744.1672374\ttest: 26778.3789618\tbest: 26776.4278584 (396)\ttotal: 4.28s\tremaining: 5.92s\n",
      "500:\tlearn: 24409.1855115\ttest: 26768.0196836\tbest: 26766.6717646 (496)\ttotal: 5.09s\tremaining: 4.62s\n",
      "600:\tlearn: 24103.1635210\ttest: 26747.7439224\tbest: 26746.6083867 (589)\ttotal: 5.92s\tremaining: 3.5s\n",
      "700:\tlearn: 23840.6585027\ttest: 26741.9395666\tbest: 26729.4261624 (658)\ttotal: 6.79s\tremaining: 2.47s\n",
      "bestTest = 26729.42616\n",
      "bestIteration = 658\n",
      "Shrink model to first 659 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  10%|█         | 1/10 [00:01<00:11,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Аналитик: обработано 984 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  20%|██        | 2/10 [00:02<00:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Бизнес-аналитик: обработано 314 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  30%|███       | 3/10 [00:03<00:08,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Дизайнер, художник: обработано 990 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  40%|████      | 4/10 [00:04<00:06,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Продуктовый аналитик: обработано 60 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  50%|█████     | 5/10 [00:05<00:05,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Руководитель проектов: обработано 515 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  60%|██████    | 6/10 [00:06<00:04,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Сетевой инженер: обработано 185 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  70%|███████   | 7/10 [00:08<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Системный администратор: обработано 1740 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  80%|████████  | 8/10 [00:09<00:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Специалист по информационной безопасности: обработано 435 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions:  90%|█████████ | 9/10 [00:10<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Специалист технической поддержки: обработано 2622 samples, найдено 30 скиллов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positions: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Позиция Технический писатель: обработано 115 samples, найдено 30 скиллов\n",
      "\n",
      "Финальные метрики:\n",
      "salary_from {'tag': 'salary_from', 'MAE': 16783.49994106978, 'R2': 0.7796603848935924, 'MAPE': 0.2230117996174036}\n",
      "salary_to {'tag': 'salary_to', 'MAE': 20263.933091395218, 'R2': 0.7196289011434797, 'MAPE': 0.2403562423382858}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#df_train_result = pd.read_csv('data/df_train_result_from_eda_2.csv')\n",
    "\n",
    "metrics = run_training(df_train_result)\n",
    "print(\"\\nФинальные метрики:\")\n",
    "for k, v in metrics.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11993d5",
   "metadata": {},
   "source": [
    "Финальные метрики:\n",
    "\n",
    "\n",
    "salary_from {'tag': 'salary_from', 'MAE': 16745.49242978005, 'R2': 0.7797999689798111, 'MAPE': 0.2220728697433952}\n",
    "\n",
    "\n",
    "salary_to {'tag': 'salary_to', 'MAE': 20273.684650250216, 'R2': 0.7192889588074074, 'MAPE': 0.24029781291166305}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19beaa40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
